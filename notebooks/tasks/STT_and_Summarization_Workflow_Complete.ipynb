{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-to-Text and Summarization Workflow\n",
    "\n",
    "In this notebook, we will explore a practical workflow for converting speech to text and summarizing the generated transcripts using HuggingFace models. This process combines automatic speech recognition (ASR) and text summarization, demonstrating how Generative AI can handle audio-to-text workflows efficiently.\n",
    "\n",
    "### Outline\n",
    "\n",
    "In this walkthrough, we will:\n",
    "\n",
    "1. **Read in an Audio File:** Load an audio file for transcription. We recommend using a publicly available audio sample, such as from the [Open Speech and Language Resources](https://www.openslr.org/12/). HuggingFace also has some common benchmarks in their `datasets` package\n",
    "2. **Stand Up an Automatic Speech Recognition (ASR) Pipeline:** Use HuggingFace's `automatic-speech-recognition` pipeline for transcription.\n",
    "3. **Generate and Save the Transcript:** Transcribe the audio file and save the output as a text file.\n",
    "4. **Read and Explore the Transcript:** Load the transcript, read a sample, and prepare it for summarization.\n",
    "5. **Summarize the Transcript:** Stand up a text-generation pipeline with the `tiiuae/Falcon3-3B-Instruct` model and summarize the transcript.\n",
    "6. **Evaluate the Summary:** Compute the ROUGE score to evaluate the quality of the generated summary.\n",
    "\n",
    "By the end of this notebook, you'll learn how to integrate ASR and summarization into an efficient workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install datasets\n",
    "! pip install bert-score\n",
    "! pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in an Audio File\n",
    "\n",
    "__Prompt__: Provide Python code to read in an audio file `\"2902-9008-0000.flac\"` using the 'soundfile' package, and play an the file within a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "audio, sampling_rate = sf.read(\"2902-9008-0000.flac\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "# Play the audio\n",
    "Audio(data=audio, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stand Up an Automatic Speech Recognition (ASR) Pipeline\n",
    "\n",
    "__Prompt__: Provide Python code to set up an ASR pipeline using HuggingFace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the ASR pipeline\n",
    "asr_pipeline = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Save the Transcript\n",
    "\n",
    "__Prompt__: Provide Python code to transcribe audio file read in by this code `audio, sampling_rate = sf.read(\"2902-9008-0000.flac\") `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe the audio file\n",
    "transcription = asr_pipeline(audio) [\"text\"]\n",
    "\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prompt__: Provide Python code to transcribe all `.flac` files in the current directory, append their transcriptions, and save them to a single text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Initialize the transcript file\n",
    "transcript_file = \"transcript.txt\"\n",
    "\n",
    "# Open the transcript file for writing\n",
    "with open(transcript_file, \"w\") as f:\n",
    "    # Iterate through all .flac files in the current directory\n",
    "    for file_name in os.listdir():\n",
    "        if file_name.endswith(\".flac\"):\n",
    "            print(f\"Processing: {file_name}\")\n",
    "            # Transcribe the audio file\n",
    "            audio, sampling_rate = sf.read(file_name) \n",
    "            transcription = asr_pipeline(audio)[\"text\"]\n",
    "            # Append the transcription to the file with a newline\n",
    "            f.write(transcription + \"\\n\")\n",
    "\n",
    "print(f\"All transcriptions saved to {transcript_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prompt__: Provide Python code to read a transcript file called \"transcript.txt\" and print some sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(transcript_file, \"r\") as f:\n",
    "    transcript_text = f.read()\n",
    "\n",
    "# Print the first few sentences\n",
    "print(\"Sample from the transcript:\")\n",
    "print(\"\\n\".join(transcript_text.split(\".\")[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the Transcript\n",
    "\n",
    "__Prompt__: Provide Python code to create a text-generation pipeline using the model of \"tiiuae/Falcon3-3B-Instruct\" from HuggingFace and use the 0th GPU. Also, make sure when creating the pipeline to specify \"max_new_tokens = 500\", and make sure the pipeline only outputs the generated text and not the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"tiiuae/Falcon3-3B-Instruct\"\n",
    "\n",
    "# Create a text-generation pipeline\n",
    "text_gen_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    device=0,  # Use the 0th GPU\n",
    "    max_new_tokens=500,\n",
    "    return_full_text=False  # Ensure the output only includes the generated text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__prompt__: Using the a huggingface text-generation pipeline called \"text_gen_pipeline\", create a prompt using an f-string to summarize text called \"transcript\" text and run that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Summarize the following transcript in one sentence. Please make the summary concise as possible:\\n{transcript_text}...\"\n",
    "summary = text_gen_pipeline(prompt)[0][\"generated_text\"]\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Summary\n",
    "\n",
    "__Prompt__: Provide Python code to calculate the BERTScore of a text called \"summary\". The original text is in a variable called \"transcript_text\". Please use the CPU for the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Calculate BERTScore\n",
    "P, R, F1 = score(\n",
    "    [summary],  # Candidate (e.g., summary)\n",
    "    [transcript_text],  # Reference (e.g., transcript)\n",
    "    lang=\"en\",  # Specify language\n",
    "    device=\"cpu\",\n",
    "    verbose=True  # Optional: enable verbose logging for debugging\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"BERTScore Precision: {P.item():.4f}\")\n",
    "print(f\"BERTScore Recall: {R.item():.4f}\")\n",
    "print(f\"BERTScore F1: {F1.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
